{"pages":[{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"About Author","text":"Self-introductionThe only thing I know is that I know nothing. I decided to start writing blogs to record interesting papers and fascinating ideas in the fields of Financial Engineering, Machine learning, Optimization, and Algorithm. I cannot promise all the phrases in my blogs are precise and rigorous, but I have tried my best to do so. If you find any mistakes and typos, please feel free to contact me. Thank you for reading my blogs. Peimou Email: ps3136@columbia.edu","link":"/about/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Hello World","text":"Some helpful links to help you blogging. How to use Hexo Hexo. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting. http://theme-next.iissnan.com/theme-settings.html (language: Chinese) https://www.jianshu.com/p/efbeddc5eb19 (language: Chinese) Math support in Hexo: Mathjax vs KatexAlthough Katexs support less mathematics symbols compared to Mathjax, Katex only takes hundreds microsecond to render math formula, which is hundred times faster than Mathjax. I appreciate Zijing Hu’s help when I struggled with the settings of Katex and hexo-renderer-kramed. You can visit Zijing’s github page for details. You can read the Katex documents to learn more about the syntax and details.","link":"/2020/01/13/Hello%20World/"},{"title":"Stochastic Approximation Methods--Notes--Part 1","text":"Generally, stochastic approximation methods are a family of iterative methods. The goal of these algorithms is to recover some properties of a function depending on random variables. The application of stochastic approximation ranges from deep learning (e.g., SGD ) to online learning methods. 1. An introduction to Stochastic Approximation MethodsIn this section, I will show you some examples of stochastic approximation methods. 1.1 Example 1: ExpectationFor a given probability space $(\\Omega, \\mathcal{F}, P)$, we want to solve the expectation of $E^P(f(\\omega))$, where $f$ is a measurable function, and $\\omega \\in \\Omega$. A reasonable solution is to estimate the expectation via arithmetic average. The following equations provide us an iterative method to this problem. Let $\\mathbb{E}_n$ be the estimation of $\\mathbb{E}^P(f(\\omega))$ given $n$ observation. $n \\times E_n = \\sum_{i = 1}^n f(\\omega_i)$ $ (n+1) \\times E_{n+1} = \\sum_{i = 1}^{n+1} f(\\omega_i) = n \\times E_n + f(\\omega_{n+1}) $ $ \\implies (n + 1) \\times E{n+1} = (n+1) \\times E_n + f(\\omega_{n+1}) - E_n $ $ \\implies E_{n+1} = E_n + \\frac{1}{n+1} [f(\\omega_{n+1}) - E_n] $ 1.2 Example 2: SGDIn the framework of stochastic gradient descent (SGD), or on-line gradient descent, the true gradient $\\nabla Q(\\omega)$ is approximated by a gradient at a single sample. Let $\\omega_n$ be the estimation of true gradient in the $nth$ iteration, then $\\omega_{n+1} = \\omega_n - \\lambda \\nabla Q(\\omega)$ where $\\lambda$ is the learning rate. There are several popular extensions of the SGD method, including Momentum, Nesterov Momentum, and Adam. 1.3 Example 3: Q-Learning in reinforcement learningIn the field of reinforcement learning, function $Q: S \\times A \\xrightarrow{} \\mathcal{R}$ combines the reward with states and actions. At each time $t$, the agent select an action $a_t$, get an reward $r_t$ from the environment, and enter into the next state $s_{t+1}$. The discussions of convergence of RL cannot avoid the topics on the Q function or the value function. $$Q^{new}(s_t, a_t) = (1 - \\alpha)Q^{old}(s_t, a_t) + \\alpha (r_t + \\gamma \\max \\limits_a Q^{old}(s_{t+1}, a))$$ where $\\alpha$ is the learning rate, and $\\gamma$ is the discount factor. 2. Robbins-Monro AlgorithmIn 1951, Robbins and Monro developed a methodology for solving a root finding problem given a function depends (or partially depends) on a random variable. Root finding problem is the generalization of several important topics, including optimizations and extrema finding. 2.1 Root finding problem without uncertaintyLet $M(x)$ be a given function and $\\alpha$ a given constant such that the equation $M(x) = a$ has a unique root $x = \\theta$. For any iterative method for this root finding problem, we find one or more initial values $\\ x_{initial}$, and then successively obtain new values as certain functions of the previous obtained $x$. The most famous algorithm is the Newton–Raphson method. 2.2 A stochastic generalization of the root finding problemLet’s consider how to solve this problem when $M(x)$ is unknown for some reason. Let’s assume the randomness of the function is captured by the probability space $(\\Omega, \\mathcal{F}, P)$, and there is a random variable $Y$ on $(\\Omega, \\mathcal{F}, P)$ which takes values in a state space $(S, \\mathcal{L})$. In this blog, we assume the state space is a d-dimensional Euclidean space equipped with the $\\sigma$-field of Borel sets. In this algorithm, $M(x)$ is a deterministic function which defined as follows: $M(x) = \\int_{y \\in S }ydH(y|x)$ where $H(y|x) = \\mathbb{P}[Y(\\omega) \\le y|x]$ ($\\omega \\in \\Omega$) is the distribution function of $Y$ given an unobservable deterministic variable $x$. In other word, $M(x)$ is the expectation of $Y$ for the given $x$. Although we know nothing about the nature of function $M(x)$ and the distribution function $H(y|x)$, but we assume (which mean this assumption will work as a known condition in the proof) that the equation $M(x) = a$ has a unique solution $x = \\theta$. Bobbins-Monro algorithm introduced a method to estimate $\\theta$ by making successive observations on $Y$ at given $x_1, x_2, …$, which are determined sequentially in accordance with some definite experimental procedure. The idea of this algorithm is to construct a transition probability between two states. Moreover, with this sequence, the difference between $\\lim \\limits_{k \\xrightarrow{} \\infty}x_k$ and $\\theta$ can be controlled. We can conclude this idea as finding a sequence $\\{x_k\\}$, such that $\\lim \\limits_{k \\xrightarrow{} \\infty}E(x_k - \\theta)^2 = 0$ This idea also implies the convergence in probability (or in $\\mathcal{L}^2$) of $x_n$ to $\\theta$. 2.3 The proof of convergence theoremThe computational origin of this algorithm is the first example (expectation estimation) in the Introduction section. If we review the expectation estimation problem in the framework of Robbins-Monro, then in this example, $x$ denotes the expectation and function $M(x) = \\mathbb{E}^P[Y - x]$, and we want to solve the equation $M(x) = 0$. I only present brief proof to show the idea. You may read this paper for more details. We want to prove that: Condition 1: For every $x$, a distribution function in $y$, and there exist a positive constant C such that $\\mathbb{P}[|Y(\\omega)| \\le C|x] = \\int_{-c}^cdH(y|x) = 1$ Condition 2: There exist finite constants $\\alpha, \\theta$ such that $M(x) \\le \\alpha$ for $x \\lt \\theta$, and $M(x) \\ge \\alpha$ for $x \\gt \\theta$ Condition 3: Let $\\{a_n\\}$ be a fixed sequence of positive constants such that $0","link":"/2020/01/13/Stochastic%20Approximation%20Methods--Notes--Part%201/"},{"title":"Kalman Filter-Notes-Part1","text":"R.E Kalman published a paper about a recursive solution to a discrete-data linear filtering problem. The Kalman filter provided us a computational method to estimate unobservable variables through minimization the posterior error. Moreover, Kalman filter enabled us to obtain the consistent parameter estimates by maximizing the likelihood function of error innovations. 1. The basis of discrete Kalman filterGenerally, Kalman filter solved the problem of estimating the unobservable state $x \\in \\mathcal{R}^n$ of a discrete time control process. The dynamic of the unobservable state’s ($n \\times 1 $ vector) can be written as: $x_k = Ax_{k - 1} + Bu_{k - 1}＋ｗ_{k - 1}$ The measurement variable $z_k$ follows a linear transformation of unobservable states with an linearly additive noise term $v_k$: $z_k = Hx_k＋v_k$ Note that we assume the probability measure of $w$ and $v$ follow Gaussian distribution with zero mean and covariance matrix Q , and R, which are both independent of each other and white. I will use the same symbols as Greg Welch and Gary Bishop’s: An introduction to Kalman filter to show you the computational origin of Kalman filter. Notations: $\\hat{x_k^{-}} \\in \\mathcal{R}^n$ is the estimation of unobservable states $x$ at time $k$ under the filtration $\\mathcal{F}_{t-1}$. $\\hat{x_k}$ is the posteriori state estimate under the information at time $k$ (with the help of $z_k$). Priori estimate error $e^{-}_{k}$: $x_k - \\hat{x_k^{-}}$. Posteriori estimate error $e_{k}$: $x_k - \\hat{x_k}$. Priori estimate error covariance matrix $P^{-}_{k} = \\mathbb{E}[e^{-}_ke^{-T}_k]$ Posteriori estimate error covariance matrix $P_{k} = \\mathbb{E}[e_ke^{T}_k]$ We assume the relationship between the posteriori estimate and the priori estimate follows: $\\hat{x_k} = \\hat{x^{-}_k} + K_k(z_k - H\\hat{x^{-}_k})$ Remark: If you know something about Gaussian distribution, you may find this is the BUE given observed states if we assume the noises is Gaussian distributed (it is a result of joint Gaussian distribution). I firmly believe this assumption is inspired from a probability origin. $z_k - H\\hat{x^{-}_k}$ are related to many frightening names like measure residual or innovation. As we need to minimize the posteriori error of each entry of the state vector, we should minimize the trace of $P_k$. Note that in the classical Kalman filter, the transition matrix of the system is deterministic. We only need to consider some incontrollable factors like measurement error and transition error. $\\hat{x_k} = \\hat{x^{-}_k} + K(z_k - Hx^{-}_k) \\leftrightarrow \\hat{x_k} = \\hat{x^{-}_k} + K(Hx_k + v_t - Hx^{-}_k)$ $\\leftrightarrow x_k - \\hat{x_k} = x_k - \\hat{x^{-}_k} - K(Hx_k + v_t - Hx^{-}_k)$ $\\leftrightarrow P_k = (I - K_kH_k)P_k^-(I - K_kH_k)^T+K_kR_kK_k^T$ (*) Let’s review some tricks in matrix derivation. You can see more details about layout with wiki. $\\frac{d(tr(AB))}{dA} = B^T$ $\\frac{d(tr(ACA^T))}{dA} = 2AC$ (It is trivial if you know $tr(AB) = \\sum_i\\sum_j a_{ij}b_{ji}$) We can get the optimal $K_k$ (the Kalman Gains): $K_k = P^{-}_kH^T(HP^{-}_kH^T+R)^{-1}$ With the Kalman gain and (*), we can get the posteriori estimates of state’s posteriori covariance matrix $P_k$. $P_k = (I - K_kH_k)P_k^-$ Note that if $\\lim \\limits{R \\xrightarrow{} 0}$ (there is no error in measurement), then the Kalman gain get the maximum value $H^{-1}$. If $\\lim \\limits{P_k^- \\xrightarrow{} 0}$, then the Kalman gain get the minimum value 0. You can see the adaptiveness of the methods here. If we are more confidence with the transition equation of unobservable state, we should allocate relatively more weight on the priori estimates; If we are more confident with the measurement of the observable equation, then we should make the posteriori estimate more close to the observable states. With the best estimated posteriori estimates of unobservable state, we can update the new priori estimate of unobservable variables. $P_k^- = AP_kA^T + Q$ $\\hat{x_k^-} = A\\hat{x_{k-1}} + Bu_{k-1}$ Remark: In the system of Kalman filter, we know exactly the transition of unobservable states. In this situation, the Kalman filter found a solution to estimate the unobservable states $x_k$ based on information at time k. If we know nothing about the transition of unobservable states (unknown A for example), we can maximize the likelihood function based on the measurement function. 2. Discussions about the initial valuesUnfortunately, we need to input four tricky initial values to the Kalman filter system: $x_0^-$, $P_0^-$, R, and Q. The more unfortunate fact is that KF is sensitive to the initial values. Based on this fact, we have to adjust hyperparameters for our model. The best statement of adjustment of initial values I have ever met is that the innovation ($z_k - H\\hat{x_k^-}$) should be a white noise with zero mean if KF works well (See Optimal State Estimation Kalman-H-and Nonlinear Approaches). We have to test different hyperparameters to help the model make sense. Thank you for reading my blog! KF is a big topic and I will dig deeper in the next parts of this Note.","link":"/2020/01/16/Kalman%20Filter-Notes-Part1/"},{"title":"Kalman Filter--Projects--Part1.5--N-factors Gaussian model","text":"Before we dig deeper in the Kalman filter, I would like to share one of the applications of Kalman filter with you. N-factors Gaussian model is a direct application of what we have discussed in Kalman filter Part1. I will give you a brief introduction about this method, and some tricks in this algorithm‘s implement. 1. The Financial basis of N-factor Gaussian modelIf you have heard Barra model for stocks or other factors analysis models, you may understand this n-factors Gaussian model easily. Factor analysis is a cross-sectional methodology, which totally depends on the information at current time slot. To be more specific, it can detect the sources of correlations if we assume the correlations between different observable states are caused by communalities. Of course, we can use factors analysis framework to predict with some extra assumptions (for example, the factors’ returns keep constant between time slots). At time $t$, we can know the return of $n$ assets. We assume that the correlations between assets are caused by $m$ factors (risk factors). Matrix $X_{(m \\times n)}$ denotes the exposures of assets on risk factors, while vector $f$ denotes the ‘return’ of risk factors. If we write this model in a linear regression scheme, then $r_t = X_t^Tf + \\epsilon$ Intuitively, we decompose the observed returns according to the risk factors, and the coefficients of factors describe the average returns of each factors. In this framework, we treat the returns of factors as constants. What if we want to treat the coefficients like a distribution or something which contains the uncertainties? Let’s review the framework of risk neutral theorem in financial engineering. We assume the market (efficient and complete) has $n$ risk factors which determine the return of observable assets. Let $\\Theta(t)$ be a n-dimensional adapted process according to $W(t)$, which is a m-dimensional Brownian motions. In this framework, the returns of the risk factors are described as a m-dimensional Brownian motion. $d\\Theta(t) = \\mu(\\Theta)dt + \\sigma(\\Theta)dW(t)$ $sigma(\\Theta)$ works the same as the risk factors exposures in this framework. From this perspective, multi-factors model in stocks is a just special case. 2. The settings of N-factors Gaussian modelWe assume the spot prices of assets ($\\mathbf{S}_t$ is a $N \\times 1$ vector)in a market can be described with $n$ risk factors as: $log\\mathbf{S_t} = \\mathbf{L}_t’ \\mathbf{x_t} + \\mu t $ $d\\mathbf{x}_t = -\\mathbf{K}\\mathbf{x}_tdt + \\mathbf{\\Sigma} d\\mathbf{W}_t$ where $\\mathbf{K} = \\begin{Bmatrix} 0 & 0 & … & 0 \\\\ 0 & k_2 & … & 0 \\\\ .. & .. & .. & .. \\\\ 0 & 0 &…&k_n \\end{Bmatrix}$, and $\\mathbf{\\Sigma} = \\begin{Bmatrix} \\sigma_1 & 0 & … & 0 \\\\ 0 & \\sigma_2 & … & 0 \\\\ .. & .. & .. & .. \\\\ 0 & 0 &…&\\sigma_n \\end{Bmatrix}$ $\\mathbf{L}_t$ is a $n \\times N$ matrix. This settings of multi-factors analysis include the independence of communalities. However, of course, we can handle the correlations between the risk factors. For example, we assume the risk factors are linear combinations of m independent factors (m < n), then the observed returns of the markets is a affined transformation of m-factor Gaussian model we showed above (See Affined N-factors Gaussian Model). 3. Parameters estimationParameters estimation is a direct application of Kalman filter (See here to know more about Kalman filter). As we have discussed in the Part I of KF Notes, we can maximize the likelihood function based on innovation ($z_t - \\hat{z_t}$) to estimate the transition matrix of unobservable states. $\\mathbf{x}_t = A \\mathbf{x}(t-1)+ \\mathbf{c}_t + \\mathbf{\\epsilon}_t$, where $\\mathbf{\\epsilon}_t \\backsim N(0, Q_t)$ $\\mathbf{z}_t = H \\mathbf{x}_t + \\mathbf{d}_t + \\mathbf{v}_t$, where $\\mathbf{v}_t \\backsim N(0, R_t)$ $\\hat{x_t^-} = A\\hat{x_{t-1}} + \\mathbf{c}_t$ $\\hat{P_t^-} = A \\hat{P_{t-1}}A^T + Q_t$ $\\hat{z_t^-} = H \\hat{\\mathbf{x}_t^-} + \\mathbf{d}_t$ Let $\\hat{F_t^-}$ be the priori covariance matrix of observable states. $\\hat{F_t^-} = H\\hat{P_t^-}H^T + R_t$ We need to parameterize the covariance matrix $R_t$. Some papers assume that the error of measurement equation is a homoscedastic diagonal matrix. However, we can try some more complex assumption, which is another typical bias and variance trade off. We need to maximize the log-likelihood function of $z_t$: $\\mathcal{L}(\\Theta) = -\\frac{1}{2} \\sum_t log|F_t^-| - \\frac{1}{2} \\sum_t [z_t - \\hat{z_t^-(\\Theta)}]^T (F_t^-)^{-1}[z_t - \\hat{z_t^-(\\Theta)}]$ If $H_t$ also needs to be parameterized, we can use EM algorithm to estimate the parameters. Remark: We used the priori estimation of the covariance matrix of $\\hat{z_t^-}$ in the likelihood function. Why not the posterior covariance matrix? The answer is quite trivial if you notice that the posterior estimation includes a weighted average of priori estimation and innovation (measure residual), which means we have to know the innovation before the posteriori estimation. In the likelihood function methodology, we use Fisher information matrix to estimate the variance of parameters.","link":"/2020/01/18/Kalman%20Filter-Projects-Part1.5/"},{"title":"Generalized methods of Moments and Newy-West Adjustment-Notes-Part 1","text":"Newy-West adjustment assures a consistent estimation given autocorrelation in samples. The origin of Newy-West is closely related to Generalized Method of Moments. This blog includes the motivations, the definition and some properties of Generalized methods of Moments. 1. Motivations of GMMLet $\\Omega$ denote the set of sample points in the underlying probability space in some estimation problem. Let E denote the expectations operator. For a stochastic process $\\{x_n: n \\ge 1\\}$ defined in this probability space, we can get a finite segment of one realization of this process, i.e., $\\{x_n(\\omega_0): 1 \\le n \\le N\\}$. This sequence can be treated as the observable data sequence. Let moments function $f(\\cdot, \\theta)$ : $R^p \\xrightarrow{} R^q$ be a continuous and continuously differentiable measurable function of $\\theta$. To be more specific, the parameter $\\theta$ is a $(q \\times 1)$ vector, and we know $q$ moment based on the underlying distribution (or probability measure). Set the population moment conditions are that $E[f(x_i, \\theta_0)] = 0$ (Note that $\\theta_0$ is the solution of system of equations based on population moments, and it is a deterministic variable given information of population). The associated sample moments are given by: $f_n(\\theta) = \\frac{1}{n} \\sum_{i = 1}^nf(x_i, \\theta)$ We want to estimate $\\theta_0$ based on the solution to the system of equations $f_n(\\theta) = 0$ (to be more specific the bias to the moments is zero). Note that we have $q - p$ additional moments (if $q < p$), and the remedy for this situation is call GMM, which was introduced by Hansen[1982]. Intuitively, if we cannot find a good enough $\\theta$ to make sure the equation system $f_n(\\theta) = 0$, then we should at least try to keep the sample moments are very close to zero. Then the strategy is to measure the distance between $f_n(\\theta)$ and $0$. 2. The definition of GMMDef: Suppose function $f$ has the properties in section 1. We have an observed sample $\\{x_i: i = 1, 2, 3, \\dots\\}$, and we want to estimate parameter vector $\\theta$ ($p \\times 1$) with true value $\\theta_0$. Let $E[f(x_i, \\theta_0)]$ denote a set of $q$ population moments and $f_n(\\theta)$ denote the associated sample counterparts. Define the criterion function $Q_n(\\theta)$ as: $Q_n(\\theta) = f_n(\\theta)^TW_nf_n(\\theta)$ where $W_n$ is the weighting matrix, which converges to a positive definite matrix $W$ as n grows large. Then the GMM estimator of $\\theta_0$ is given by $\\hat{\\theta} = \\argmin Q_n(\\theta)$ Note the $Q_n(\\theta)$ measure the distance between $\\theta$ and $\\theta_0$, since $f_n(\\theta_0)$ should converge to zero with probability. In conclusion, we try to measure the distance between $\\theta_0$ and $\\theta$ in a metric space. If $p = q$, then the GMM degenerate to MM. 3. The property of GMM3.1 AssumptionsGiven some assumptions, we can conclude that the GMM estimator as given in section 2 is consistent and asymptotically normally distributed. Assumption 1: we have more moments than parameter; the rank of Jacobian matrix of the moment equations evaluated at $\\theta_0$ is at least p; $\\theta_0$ is the unique solution of the moments equations system. Assumption 2: The law of weak large number law holds, which mean for any $\\epsilon > 0$, we have $\\lim \\limits_{n \\xrightarrow{} \\infty }\\mathbb{P}[|f_n(\\theta_0) - f(\\theta_0)| > \\epsilon] = 0$. Assumption 3: The sample moments obey a central limit theorem, with a finite asymptotic covariance matrix $\\frac{1}{n}F$. 3.2 The distribution of GMM estimatorThe variance of GMM estimator is consistent and asymptotically normally distributed with asymptotic covariance matrix $V_{GMM}$ $V_{GMM} = \\frac{1}{n} [G(\\theta_0)^{T}WG(\\theta_0)]^{-1}G(\\theta_0)^{T}WFWG(\\theta_0) [G(\\theta_0)^{T}WG(\\theta_0)]^{-1}$ where $G(\\theta_0)$ is the Jacobian matrix of the population moment functions evaluated at the true parameter value $\\theta_0$. I give up to articulate the proof of this result due to the complexity (due to my weak asymptotic statistic foundation QAQ) (See here for more details). Note that the variance of GMM estimator depends on the choice of $W_n$. If we review the criterion function of GMM, we can deduce that this distance function is the sample moment’s error sum of squares. Note that, given the knowledge of conditions of a matrix ($\\frac{\\lambda_{max}}{\\lambda_{min}}$) and Gaussian-Markov condition, it is make sense to normalize the errors in the moments by their variance. (Recall WLS and Hat Matrix ) 3.3 The optimal weighting matrixThe optimal choice of the weighting matrix $W_n = F^{-1}$, the GMM estimator is a asymptotically efficient with covariance matrix: $V_{GMM}^* = \\frac{1}{n} [G(\\theta_0)^TF^{-1}G(\\theta_0)]^{-1}$ However, if we want to know matrix $F$ (the asymptotic covariance matrix of sample moments), we have to estimate $\\theta$ first (Recall EM algorithm). Then we solve this circularity by adopting a multi-step method: Step 1: Choose a sub-optimal weighting matrix ($I$ for example), this will give us a consistent estimation of $\\theta$. Then we can estimate the matrix $F$. Step 2: Use the new $F$, estimate $\\theta_0$ Reference Zsochar, P. Short Introduction to the Generalized Method of Moments. HUNGARIAN STATISTICAL REVIEW. Hansen, L. (1982). Large Sample Properties of Generalized Method of Moments Estimators. Econometrica, 50(4), 1029. doi: 10.2307/1912775","link":"/2020/01/31/GMM_Newy_West_1/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Katex","slug":"Katex","link":"/tags/Katex/"},{"name":"Optimization","slug":"Optimization","link":"/tags/Optimization/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Kalman Filter","slug":"Kalman-Filter","link":"/tags/Kalman-Filter/"},{"name":"Optimal Control","slug":"Optimal-Control","link":"/tags/Optimal-Control/"},{"name":"N-factors Gaussian Model in Finance","slug":"N-factors-Gaussian-Model-in-Finance","link":"/tags/N-factors-Gaussian-Model-in-Finance/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"},{"name":"GMM","slug":"GMM","link":"/tags/GMM/"}],"categories":[{"name":"Tutorials","slug":"Tutorials","link":"/categories/Tutorials/"},{"name":"Notes","slug":"Notes","link":"/categories/Notes/"},{"name":"Projects","slug":"Projects","link":"/categories/Projects/"}]}